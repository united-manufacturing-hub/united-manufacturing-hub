# Copyright 2023 UMH Systems GmbH
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---
{{if .Values.tags.classic }}

apiVersion: apps/v1
kind: Deployment
metadata:
  # This is the name of the component, it should be unique within the namespace (63 chars max as per RFC 1035/1123)
  name: dfc-3e5c91f6-3dfc-45d6-8e9b-f17705e07b4c-kafka-to-psql-historian
  # To be scheduled in the open-source namespace
  namespace: united-manufacturing-hub
  labels:
    # This does not change over time
    data-flow-component-uuid: 3e5c91f6-3dfc-45d6-8e9b-f17705e07b4c
    # This is the random UUID of the version of the component
    data-flow-component-version-uuid: 0edc0bc1-7df2-4fb8-ad90-955ad1aacc04
    # Timestamp of last change to the component in unix milliseconds since epoch
    data-flow-version: '1730983044602'
    # Generic label to indicate that this is a data flow component
    is-data-flow-component: 'true'
    # Required for mgmtcompanion to manage the component
    managed-by: mgmtcompanion
    # Do not allow mgmtcompanion to modify the component
    data-flow-component-is-read-only: 'true'
    # The type of the component
    data-flow-component-type: bridge
spec:
  replicas: 1
  selector:
    matchLabels:
      data-flow-component-uuid: 3e5c91f6-3dfc-45d6-8e9b-f17705e07b4c
  template:
    metadata:
      labels:
        # This does not change over time
        data-flow-component-uuid: 3e5c91f6-3dfc-45d6-8e9b-f17705e07b4c
        # This is the random UUID of the version of the component
        data-flow-component-version-uuid: 0edc0bc1-7df2-4fb8-ad90-955ad1aacc04
        # Timestamp of last change to the component in unix milliseconds since epoch
        data-flow-version: '1730983044602'
        # Generic label to indicate that this is a data flow component
        is-data-flow-component: 'true'
        # Required for mgmtcompanion to manage the component
        managed-by: mgmtcompanion
        # Do not allow mgmtcompanion to modify the component
        data-flow-component-is-read-only: 'true'
        # The type of the component
        data-flow-component-type: bridge
    spec:
      volumes:
        - name: config
          configMap:
            name: dfc-3e5c91f6-3dfc-45d6-8e9b-f17705e07b4c-kafka-t-psql-historian
      initContainers:
        # This init container waits for Postgres and Kafka to be available before starting the main container
        # While not strictly necessary, it keeps the benthos logs cleaner
        - name: wait-for-postgres-and-kafka
          image: busybox
          command:
            - sh
            - -c
            - |
              # Wait for PostgreSQL (300 seconds timeout)
              TIMEOUT_PG=300
              while [[ $TIMEOUT_PG -gt 0 ]]; do
                if nc -z united-manufacturing-hub.united-manufacturing-hub.svc.cluster.local 5432; then
                  echo "PostgreSQL is ready."
                  break
                fi
                echo "Waiting for PostgreSQL... $TIMEOUT_PG seconds left"
                sleep 5
                TIMEOUT_PG=$((TIMEOUT_PG - 5))
              done
              if [[ $TIMEOUT_PG -le 0 ]]; then
                echo "PostgreSQL not available, proceeding anyway."
              fi

              # Wait for Kafka (300 seconds timeout)
              TIMEOUT_KAFKA=300
              while [[ $TIMEOUT_KAFKA -gt 0 ]]; do
                if nc -z united-manufacturing-hub-kafka.united-manufacturing-hub.svc.cluster.local 9092; then
                  echo "Kafka is ready."
                  break
                fi
                echo "Waiting for Kafka... $TIMEOUT_KAFKA seconds left"
                sleep 5
                TIMEOUT_KAFKA=$((TIMEOUT_KAFKA - 5))
              done
              if [[ $TIMEOUT_KAFKA -le 0 ]]; then
                echo "Kafka not available, proceeding anyway."
              fi
      containers:
        - name: dfc-3e5c91f6-3dfc-45d6-8e9b-f17705e07b4c-kafka-t-psql-historian
          image: management.umh.app/oci/united-manufacturing-hub/benthos-umh:0.4.2
          ports:
            - name: http
              containerPort: 4195
              protocol: TCP
          volumeMounts:
            - name: config
              readOnly: true
              mountPath: /benthos.yaml
              subPath: benthos.yaml
          livenessProbe:
            httpGet:
              path: /ping
              port: http
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: http
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          imagePullPolicy: IfNotPresent
          resources:
              limits:
                cpu: {{ (((.Values._004_epConfig).kafka_to_postgres_historian).limit).cpu | default "500m" }}
                memory: {{ (((.Values._004_epConfig).kafka_to_postgres_historian).limit).memory | default "450Mi" }}
              requests:
                cpu: {{ (((.Values._004_epConfig).kafka_to_postgres_historian).request).cpu | default "400m" }}
                memory: {{ (((.Values._004_epConfig).kafka_to_postgres_historian).request).memory | default "300Mi" }}
      restartPolicy: Always
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
{{end}}